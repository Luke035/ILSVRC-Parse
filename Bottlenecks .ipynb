{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from PIL import Image\n",
    "#Inception preprocessing code from https://github.com/tensorflow/models/blob/master/slim/preprocessing/inception_preprocessing.py\n",
    "#useful to maintain training dimension\n",
    "#from utils import inception_preprocessing\n",
    "from preprocessing import inception_preprocessing\n",
    "import sys\n",
    "\n",
    "#from inception import inception\n",
    "'''\n",
    "Uso di slim e nets_factory (come per SLIM Tensorflow https://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py)\n",
    "per il ripristino della rete. \n",
    "\n",
    "Le reti devono essere censite in nets_factory (v. struttura file nella directory di questo notebook)\n",
    "'''\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "from nets import nets_factory, inception_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_IMAGE_NET_ROOT_DIR ='/var/ifs/data/hadoop-cloudera5/notebookDir/HUB/lgrazioli/ILSVRC Analysis/SMALL_ILSVRC/'\n",
    "IMAGE_DF_PATH = SAMPLE_IMAGE_NET_ROOT_DIR + 'images_df.csv'\n",
    "ENI_ROOT_DIR_LOGOS = '/var/ifs/data/Eni_logo/'\n",
    "TF_RECORD_SIZE = 128\n",
    "\n",
    "#Global Variables\n",
    "IMAGE_NET_ROOT_PATH = '/var/ifs/data/tiny-imagenet-200/'\n",
    "#IMAGE_NET_ROOT_PATH = '/data/lgrazioli/'\n",
    "IMAGE_NET_LABELS_PATH = IMAGE_NET_ROOT_PATH + 'words.txt'\n",
    "IMAGE_NET_TRAIN_PATH = IMAGE_NET_ROOT_PATH + 'train/'\n",
    "TRAINING_CHECKPOINT_DIR = '/tmp/ImageNetTrainTransfer'\n",
    "#Transfer learning CHECKPOINT PATH\n",
    "#File ckpt della rete\n",
    "CHECKPOINT_PATH = '/var/ifs/data/model-zoo/inceptionv4/tensorflow-1.2/inception_v4.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n03075370/n03075370...</td>\n",
       "      <td>n03075370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n04081281/n04081281...</td>\n",
       "      <td>n04081281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n04081281/n04081281...</td>\n",
       "      <td>n04081281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n04044716/n04044716...</td>\n",
       "      <td>n04044716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n01698640/n01698640...</td>\n",
       "      <td>n01698640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n04044716/n04044716...</td>\n",
       "      <td>n04044716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n04081281/n04081281...</td>\n",
       "      <td>n04081281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n02992529/n02992529...</td>\n",
       "      <td>n02992529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n04131690/n04131690...</td>\n",
       "      <td>n04131690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/ILSVRC/Data/CLS-LOC/train/n01728920/n01728920...</td>\n",
       "      <td>n01728920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path      label\n",
       "0  /ILSVRC/Data/CLS-LOC/train/n03075370/n03075370...  n03075370\n",
       "1  /ILSVRC/Data/CLS-LOC/train/n04081281/n04081281...  n04081281\n",
       "2  /ILSVRC/Data/CLS-LOC/train/n04081281/n04081281...  n04081281\n",
       "3  /ILSVRC/Data/CLS-LOC/train/n04044716/n04044716...  n04044716\n",
       "4  /ILSVRC/Data/CLS-LOC/train/n01698640/n01698640...  n01698640\n",
       "5  /ILSVRC/Data/CLS-LOC/train/n04044716/n04044716...  n04044716\n",
       "6  /ILSVRC/Data/CLS-LOC/train/n04081281/n04081281...  n04081281\n",
       "7  /ILSVRC/Data/CLS-LOC/train/n02992529/n02992529...  n02992529\n",
       "8  /ILSVRC/Data/CLS-LOC/train/n04131690/n04131690...  n04131690\n",
       "9  /ILSVRC/Data/CLS-LOC/train/n01728920/n01728920...  n01728920"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df = pd.read_csv(IMAGE_DF_PATH)\n",
    "#Eni Images\n",
    "eni_paths = []\n",
    "eni_labels = []\n",
    "for eni_img in os.listdir(ENI_ROOT_DIR_LOGOS):\n",
    "    eni_paths.append(ENI_ROOT_DIR_LOGOS + eni_img)\n",
    "    eni_labels.append('ENI')\n",
    "    \n",
    "full_images_paths = list(images_df['path']) + eni_paths\n",
    "full_images_labels = list(images_df['label']) + eni_labels\n",
    "\n",
    "full_images_df = pd.DataFrame(full_images_paths, columns=['path'])\n",
    "full_images_df['label'] = full_images_labels\n",
    "full_images_df = full_images_df.sample(frac=1).reset_index(drop=True)\n",
    "full_images_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to list\n",
    "path_list = list(full_images_df['path'])\n",
    "label_list = list(full_images_df['label'])\n",
    "\n",
    "#Replace Paths with SIMPLE ILSVRC\n",
    "for idx,path in enumerate(path_list):\n",
    "    path_list[idx] = path.replace('/ILSVRC/', SAMPLE_IMAGE_NET_ROOT_DIR)\n",
    "    \n",
    "#Construct label dictionary \n",
    "label_dict = {}\n",
    "for idx, value in enumerate(set(label_list)):\n",
    "    label_dict[value] = idx \n",
    "label_indices = [label_dict[label] for label in label_list]\n",
    "num_classes = len(label_dict)\n",
    "#Len of path must be the same of label len\n",
    "assert len(label_indices) == len(path_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-136cca11ec88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mfull_color_path_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfull_color_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#Nonostante le annotations non tutte le immagini sono a colori\n",
    "uncorrect_images = 0\n",
    "full_color_path_images = []\n",
    "full_color_labels = []\n",
    "for idx,p in enumerate(path_list):\n",
    "    im = np.array(Image.open(p))\n",
    "    if im.shape[-1] == 3:\n",
    "        full_color_path_images.append(path_list[idx])\n",
    "        full_color_labels.append(label_indices[idx])\n",
    "    else:\n",
    "        uncorrect_images += 1\n",
    "    if uncorrect_images % 10 == 0:\n",
    "        sys.stdout.write(\"\\r\"+str(uncorrect_images))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_df = pd.DataFrame(full_color_path_images,columns=['path'])\n",
    "checkpoint_df['labels'] = full_color_labels\n",
    "checkpoint_df.to_csv('checkpoint_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_df = pd.read_csv('checkpoint_df.csv')\n",
    "full_color_path_images = list(checkpoint_df['path'])\n",
    "full_color_labels = list(checkpoint_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENI': 4,\n",
       " 'n01698640': 7,\n",
       " 'n01728920': 2,\n",
       " 'n01729977': 0,\n",
       " 'n02071294': 1,\n",
       " 'n02672831': 6,\n",
       " 'n02992529': 5,\n",
       " 'n03075370': 10,\n",
       " 'n04044716': 3,\n",
       " 'n04081281': 9,\n",
       " 'n04131690': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int64_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of int64s.\n",
    "    Args:\n",
    "        values: A scalar or list of values.\n",
    "    Returns:\n",
    "        a TF-Feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "def float_feature(values):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "\n",
    "def bytes_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of bytes.\n",
    "    Args:\n",
    "        values: A string.\n",
    "    Returns:\n",
    "        a TF-Feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=values))\n",
    "\n",
    "\n",
    "def bottlenecks_to_tfexample(bottlenecks, labels, paths):\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "      'bottlenecks/encoded': float_feature(bottlenecks),\n",
    "      'bottlenecks/label': int64_feature(labels),\n",
    "      'bottlenecks/paths': bytes_feature(paths)  \n",
    "    }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_tfrecord_filename = 'inception_bootlenecks_batch{0}.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 128\n",
    "#Serve per capire quando il generatore è passato a batch appartenenti a una nuova epoca \n",
    "BATCH_PER_EPOCH = np.ceil(len(path_list) / BATCH_SIZE)\n",
    "\n",
    "def parse_single_image(filename_queue):\n",
    "    #Dequeue a file name from the file name queue\n",
    "    #filename, y = filename_queue.dequeue()\n",
    "    #Non bisogna invocare il dequeue il parametro della funziona è già lo scodamento\n",
    "    filename, y_numeric = filename_queue[0], filename_queue[1]\n",
    "    #A y manca solo il one-hot\n",
    "    #y = tf.one_hot(y_numeric, num_classes)\n",
    "    #y = y_numeric\n",
    "    #Read image\n",
    "    raw = tf.read_file(filename)\n",
    "    #convert in jpg (in GPU!)\n",
    "    jpeg_image = tf.image.decode_jpeg(raw)\n",
    "    #Preprocessing with inception preprocessing\n",
    "    #jpeg_image = tf.image.resize_images(jpeg_image, [300, 300], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    #Inception v4 default image size is 299\n",
    "    jpeg_image = inception_preprocessing.preprocess_for_eval(jpeg_image, 299, 299)\n",
    "    jpeg_image = tf.reshape(jpeg_image, [299, 299, 3])\n",
    "    \n",
    "    #jpeg_image = inception_preprocessing.preprocess_image(jpeg_image, 300, 300, is_training=False)\n",
    "    return jpeg_image, y_numeric, filename\n",
    "#jpeg_image = parse_single_image(filename_queue)\n",
    "\n",
    "def get_batch(filenames, labels, batch_size, num_epochs=None):\n",
    "    \n",
    "    #Coda lettura file, slice_input_producer accetta una lista di liste (stessa dimensione)\n",
    "    #Risultato dello scodamento è l'elemento corrente di ciascuna delle liste\n",
    "    #Le liste sono rispettivamente la lista di file e la lista dei label\n",
    "    filename_queue = tf.train.slice_input_producer([filenames, labels])\n",
    "    \n",
    "    #Lettura singolo record\n",
    "    #jpeg_image,y,filename,y_numeric = parse_single_image(filename_queue)\n",
    "    jpeg_image,y,filename = parse_single_image(filename_queue)\n",
    "    \n",
    "    # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "    #   from -- bigger means better shuffling but slower start up and more\n",
    "    #   memory used.\n",
    "    # capacity must be larger than min_after_dequeue and the amount larger\n",
    "    #   determines the maximum we will prefetch.  Recommendation:\n",
    "    #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    min_after_dequeue = 10\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    \n",
    "    #tensors è la lista dei tensori delle single feature e immagini. Esegue batch_size volte i tensori example e label per ottenere il batch\n",
    "    #num_threads incrementa effettivamente l'utilizzo della CPU (confermato dal throughput visisible sul cloudera manager,\n",
    "    #resta comunque un throughput lento ....\n",
    "    example_batch = tf.train.shuffle_batch(\n",
    "        tensors=[jpeg_image, y,filename], batch_size=batch_size, capacity=capacity,\n",
    "        min_after_dequeue=min_after_dequeue, allow_smaller_final_batch=True, num_threads=3)\n",
    "    \n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    with tf.name_scope('preprocessing') as scope:\n",
    "        #x,y,filenames,y_numeric = get_batch(full_color_path_images, full_color_labels, batch_size=BATCH_SIZE)\n",
    "        x,y,filenames = get_batch(full_color_path_images, full_color_labels, batch_size=BATCH_SIZE)\n",
    "\n",
    "        #x = tf.contrib.layers.flatten(x)\n",
    "        #flatten_x = tf.contrib.layers.flatten(x) \n",
    "        \n",
    "with tf.device('/gpu:0'):\n",
    "    #inception prelogits \n",
    "    inception_v4.inception_v4(x,is_training=False, dropout_keep_prob=1, create_aux_logits=False)\n",
    "    #prelogits = tf.placeholder(tf.float32, [None, 1536], name='prelogits_placeholder')\n",
    "    inception_logits = tf.get_default_graph().get_tensor_by_name(\"InceptionV4/Logits/PreLogitsFlatten/Reshape:0\")\n",
    "    \n",
    "init = tf. global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch = int(np.ceil(len(full_color_path_images) / BATCH_SIZE))\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch0.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch1.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch2.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch3.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch4.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch5.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch6.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch7.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch8.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch9.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch10.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch11.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch12.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch13.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch14.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch15.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch16.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch17.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch18.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch19.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch20.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch21.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch22.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch23.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch24.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch25.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch26.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch27.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch28.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch29.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch30.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch31.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch32.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch33.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch34.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch35.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch36.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch37.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch38.tfrecord tfrecord\n",
      "<class 'numpy.ndarray'>\n",
      "(196608,)\n",
      "Producing incpetion_bootlenecks_batch39.tfrecord tfrecord\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: preprocessing/shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_INT32, DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](preprocessing/shuffle_batch/random_shuffle_queue, preprocessing/Reshape, preprocessing/input_producer/Gather_1, preprocessing/input_producer/Gather)]]\n"
     ]
    }
   ],
   "source": [
    "#GPU config\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#Saver per restoring inception net\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    #Start populating the filename queue.\n",
    "    coord = tf.train.Coordinator()\n",
    "    #Senza questa chiamata non partono i thread per popolare la coda che permette di eseguire la read\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    current_batch = 0\n",
    "    while True:\n",
    "        #x_batch, y_batch = sess.run([x,y])\n",
    "        #print(x_batch.shape)\n",
    "    \n",
    "        batch_logits, batch_y, batch_filenames = sess.run([inception_logits,y,filenames])\n",
    "\n",
    "        with tf.python_io.TFRecordWriter(output_tfrecord_filename.format(current_batch)) as tf_record_writer:\n",
    "            print(\"Producing {0} tfrecord\".format(output_tfrecord_filename.format(current_batch)))\n",
    "            example = bottlenecks_to_tfexample(bottlenecks=[float(x) for x in list(batch_logits.flatten('F'))],\n",
    "                                               labels=list(batch_y.flatten('F')), \n",
    "                                               paths=list(batch_filenames.flatten('F'))\n",
    "                                              )\n",
    "            tf_record_writer.write(example.SerializeToString())\n",
    "        #print(batch_logits.shape)\n",
    "        #print(batch_y.shape)\n",
    "        #print(batch_filenames.shape)\n",
    "        current_batch += 1\n",
    "        if current_batch >= total_batch:\n",
    "            break\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
